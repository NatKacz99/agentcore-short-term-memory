{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "from langgrpah.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "from langgraph_checkpoint_aws import AgentCoreMemorySaver\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "\n",
    "region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "logging.getLogger(\"math-agent\").setLevel(logging.DEBUG)\n",
    "\n",
    "memory_name = \"MathLanggraphAgent\"\n",
    "client = MemoryClient(region_name=region)\n",
    "memory = client.create_or_get_memory(name=memory_name)\n",
    "memory_id = memory['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"global.anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
    "\n",
    "checkpointer = AgentCoreMemorySaver(memory_id, region_name=region)\n",
    "\n",
    "llm = init_chat_model(MODEL_ID, model_provider=\"bedrock_converse\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b31e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int):\n",
    "    \"\"\"Add two intergers and return the result\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply two integers and return the result\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff120f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=\"You are a helpful assistant\",\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d4796",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-1\",\n",
    "        \"actor_id\": \"react-agent-1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What is 1337 times 515321? Then add 412 and return the value to me.\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in graph.get_state(config).values.get(\"messages\"):\n",
    "    print(f\"{message.type}: {message.text()}\")\n",
    "    print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ab182",
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint in graph.get_state_history(config):\n",
    "    print(\n",
    "        f\"(Checkpoint ID {checkpoint.config['configurable']['checkpoint_id']} of messages in state: {len(checkpoint.values.get('messages'))})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bca0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What are the first calculations I asked you to do?\"}]}\n",
    "\n",
    "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread-id\": \"session-2\",\n",
    "        \"actor-id\": \"react-agent-1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What values did I ask you to multiply and add?\"}]}\n",
    "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
